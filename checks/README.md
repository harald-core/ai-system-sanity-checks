# Sanity Checks

This folder contains a small, ordered set of conceptual sanity checks for AI-driven systems.

These are not implementation guides.
They are not best practices.
They are prompts for architectural reasoning.

Each check isolates a specific failure pattern that often appears quietly,
long before metrics or incidents make it visible.

Read them slowly.
Individually.
Out of context of tools, frameworks, or models.

If a system feels “mostly fine” but increasingly hard to reason about,
these checks are meant to surface why.
